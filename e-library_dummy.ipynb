{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMTCsGokukXtjSl230+LFp6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["pip install pandas faker"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PoHM6iB7oYu7","executionInfo":{"status":"ok","timestamp":1720447010857,"user_tz":-420,"elapsed":15050,"user":{"displayName":"Adi Heri","userId":"13971415208620944217"}},"outputId":"9ed5fd86-046f-41d9-f6b5-34de7cbe30b0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n","Collecting faker\n","  Downloading Faker-26.0.0-py3-none-any.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Installing collected packages: faker\n","Successfully installed faker-26.0.0\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"o0Iv7cannnw3","executionInfo":{"status":"ok","timestamp":1720447016770,"user_tz":-420,"elapsed":1312,"user":{"displayName":"Adi Heri","userId":"13971415208620944217"}}},"outputs":[],"source":["import pandas as pd\n","from faker import Faker\n","import random\n","\n","fake = Faker()\n","\n","# Generating data for Libraries\n","libraries = []\n","for _ in range(10):  # Assuming we have 10 libraries\n","    libraries.append([fake.unique.random_int(min=1, max=1000), fake.company(), fake.address()])\n","\n","df_libraries = pd.DataFrame(libraries, columns=['library_id', 'name', 'location'])\n","df_libraries.to_csv('libraries.csv', index=False)\n","\n","# Generating data for Categories\n","categories = [\n","    [1, 'Self-Improvement'],\n","    [2, 'Biography'],\n","    [3, 'Fantasy'],\n","    [4, 'Romance'],\n","    [5, 'Science Fiction']\n","]\n","\n","df_categories = pd.DataFrame(categories, columns=['category_id', 'category_name'])\n","df_categories.to_csv('categories.csv', index=False)\n","\n","# Generating data for Authors\n","authors = []\n","for _ in range(20):  # Assuming we have 20 authors\n","    authors.append([fake.unique.random_int(min=1, max=1000), fake.name()])\n","\n","df_authors = pd.DataFrame(authors, columns=['author_id', 'author_name'])\n","df_authors.to_csv('authors.csv', index=False)\n","\n","# Generating data for Books\n","books = []\n","for _ in range(100):  # Assuming we have 100 books\n","    books.append([fake.unique.random_int(min=1, max=1000), fake.sentence(nb_words=5), random.choice(authors)[0], random.choice(categories)[0], fake.random_int(min=1, max=20)])\n","\n","df_books = pd.DataFrame(books, columns=['book_id', 'title', 'author_id', 'category_id', 'quantity'])\n","df_books.to_csv('books.csv', index=False)\n","\n","# Generating data for LibraryBooks\n","library_books = []\n","for library in libraries:\n","    for book in books:\n","        library_books.append([library[0], book[0], fake.random_int(min=1, max=10)])\n","\n","df_library_books = pd.DataFrame(library_books, columns=['library_id', 'book_id', 'quantity'])\n","df_library_books.to_csv('library_books.csv', index=False)\n","\n","# Generating data for Users\n","users = []\n","for _ in range(100):  # Assuming we have 100 users\n","    users.append([fake.unique.random_int(min=1, max=1000), fake.name(), fake.phone_number(), fake.email(), fake.password()])\n","\n","df_users = pd.DataFrame(users, columns=['user_id', 'name', 'contact', 'email', 'password'])\n","df_users.to_csv('users.csv', index=False)\n","\n","# Generating data for Loans\n","loans = []\n","for _ in range(300):  # Assuming we have 300 loan records\n","    user = random.choice(users)\n","    library = random.choice(libraries)\n","    book = random.choice(books)\n","    loan_date = fake.date_between(start_date='-2y', end_date='today')\n","    due_date = loan_date + pd.DateOffset(days=14)\n","    return_date = loan_date + pd.DateOffset(days=random.randint(1, 14)) if random.choice([True, False]) else None\n","    loans.append([fake.unique.random_int(min=1, max=1000), user[0], library[0], book[0], loan_date, due_date, return_date])\n","\n","df_loans = pd.DataFrame(loans, columns=['loan_id', 'user_id', 'library_id', 'book_id', 'loan_date', 'due_date', 'return_date'])\n","df_loans.to_csv('loans.csv', index=False)\n","\n","# Generating data for Holds\n","holds = []\n","for _ in range(200):  # Assuming we have 200 hold records\n","    user = random.choice(users)\n","    library = random.choice(libraries)\n","    book = random.choice(books)\n","    hold_date = fake.date_between(start_date='-2y', end_date='today')\n","    status = random.choice(['active', 'expired'])\n","    holds.append([fake.unique.random_int(min=1, max=1000), user[0], library[0], book[0], hold_date, status])\n","\n","df_holds = pd.DataFrame(holds, columns=['hold_id', 'user_id', 'library_id', 'book_id', 'hold_date', 'status'])\n","df_holds.to_csv('holds.csv', index=False)\n"]}]}